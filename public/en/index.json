


[{"content":"","date":"2024-04-07","externalUrl":null,"permalink":"/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","section":"Tags","summary":"","title":"图神经网络","type":"tags"},{"content":" 图神经网络学习笔记（1） # 图网络 # 背景 # ​\t常见的神经网络，如BP神经网络可以用来处理表格型的数据，卷积神经网络可以用来处理图片数据，循环神经网络则可以用来处理序列数据，这些数据都是结构化的数据，当我们需要处理的数据为图这种非结构化的数据，例如：城市交通的每个路口上的传感器所记录的数据；化学分子结构；人际关系网；推荐系统中每个人构成的图。并不是说以上的神经网络处理不了图这种类型的数据，只是在处理图这种数据上存在欠缺，图数据有一个很明显的特征，相邻或相近的节点存在一定的空间依赖关系，这种关系传统神经网络很难捕获。为了获取表示这种特征关系，图网络就此诞生。\n内容 # ​\t图网络的核心思想就是依据图结构的空间依赖关系来表征现实世界中真实的特征之间的相互作用关系，通过对节点特征进行聚合生成新的节点特征表示用于后续工作。\n​\t下图为一张交通系统的图结构，在6个位置上分别有一个传感器记录了一段时间的交通流量数据，现在的目标是要预测接下来每个位置上未来一段时间的流量。如果从传统的时间序列模型来思考，未来的数据一定是与过去的数据相关，因此我们可以对6个位置的时间序列单独进行预测生成6个位置未来的预测值，但是这样就没有考虑到节点之间的空间依赖关系。既然已经用图结构表示出了这种空间关系，那么我们怎么去应用它？这就是图网络所要解决的问题。\nGCN(Graph Convolutional Network) # 论文：https://arxiv.org/pdf/1609.02907.pdf\n​\tGCN（图卷积神经网络），实际上跟CNN（卷积神经网络）的作用一样，就是一个特征提取器，只不过它的对象是图数据。GCN精妙地设计了一种从图数据中提取特征的方法，从而让我们可以使用这些特征去对图数据进行节点分类（node classification）、图分类（graph classification）、边预测（link prediction），还可以顺便得到图的嵌入表示（graph embedding）。下图为GCN和输入图像数据的CNN间的对比。\n计算原理 # ​\t假设有一批图数据，其中有N个节点（node），每个节点都有自己的特征，假设特征一共有D个，我们设这些节点的特征组成一个N×D维的矩阵X，然后各个节点之间的关系也会形成一个N×N维的矩阵A，也称为邻接矩阵（adjacency matrix）。X和A便是我们模型的输入。\nGCN算法的步骤简单可总结为：聚类、更新、循环\n设输入为X，网络权重为W，则一层的BP网络可以表示为 \\( f = \\sigma(XW) \\) ；图卷积网络可以表示为： \\( f = \\sigma(AXW) \\)，其中A为图结构的表示矩阵。他们分别是什么含义？\n更新中 # 信息传播\n邻接矩阵\n度矩阵\n","date":"2024-04-07","externalUrl":null,"permalink":"/posts/gnn_pt1/","section":"文章","summary":"","title":"图神经网络学习笔记（1）","type":"posts"},{"content":"","date":"2024-04-07","externalUrl":null,"permalink":"/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","section":"Tags","summary":"","title":"学习笔记","type":"tags"},{"content":"","date":"2024-04-07","externalUrl":null,"permalink":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","section":"Tags","summary":"","title":"机器学习","type":"tags"},{"content":" This page is translated by GPT-4\nThis article is a reprint of a setup guide I wrote during my internship, and the content has been anonymized.\nWhy this？ # Jupyter Lab is a web-based interactive development environment that allows users to edit, run, and share code visually. Users can execute code step by step, which is suitable for tasks such as data analysis, scientific computing, machine learning, etc. Especially for data processing tasks like PySpark, using Jupyter displays the results of each process, facilitating a deeper understanding of data processing and code learning.\nzsh is an alternative to bash, offering almost the same functionality. However, with a configuration management tool like oh-my-zsh, zsh can install various plugins and themes, allowing users to customize it according to their needs and preferences, thereby enhancing development efficiency.\nConfiguring Jupyter # First, enter your own environment on the server\nssh your_server_address Installing Anaconda # Download the installation script from Tsinghua mirror source https://repo.anaconda.com/archive/. Please choose the version corresponding to the server architecture.\nExecute the installation script in your own environment on the server. After proceeding with yes, it will by default install in the path ~/anaconda3. Try running conda \u0026ndash;version to check if it\u0026rsquo;s successfully installed. If the command is not found, try re-entering or source ~/.bashrc.\nInstalling Jupyter # Create a sub-environment to install common Jupyter packages. Change the name after -n to your own environment name.\nconda create -n py3.7_env python=3.7 jupyterlab numpy pandas scipy Add the following content at the end of ~/.bashrc, which sets the environment with Jupyter installed as the default start-up and configures common hdfs commands. Change the first line\u0026rsquo;s environment name to the one you previously created, and change HHOME and sp to your name.\nconda activate py3.7_env export HADOOP_USER_NAME=xxx export HADOOP_USER_PASSWORD=xxx export HHOME=\u0026#39;/user/bigdata-dp/your_name\u0026#39; export LD_LIBRARY_PATH=/lib:/usr/lib:/usr/local/lib alias hls=\u0026#34;hadoop fs -ls\u0026#34; alias hget=\u0026#34;hadoop fs -get\u0026#34; alias hput=\u0026#34;hadoop fs -put\u0026#34; alias hcat=\u0026#34;hadoop fs -cat\u0026#34; alias http=\u0026#34;python -m http.server\u0026#34; alias hdu=\u0026#34;hadoop fs -du -h\u0026#34; Setting Up Startup Script # Navigate to the path /home/odin/your_name/anaconda3/envs. Please replace the name with your own.\nExecute tar -czvf my_py37.tar ./py3.7_env to package the conda environment. Please replace the environment name and tar package name with your own.\nUpload the created tar package to the designated directory in hdfs.\nEdit start_jupyter.sh and add the following content, noting that you need to replace the following:\nIn PYSPARK_DRIVER_PYTHON_OPTS, the IP is the server IP, and you can choose any port that is not occupied. Change pyspark \u0026ndash;name to the name you have chosen. Change the path under \u0026ndash;archives to the path of the tar package previously uploaded to hdfs. Change spark.yarn.appMasterEnv.PYSPARK_PYTHON to your name\u0026rsquo;s path. export HADOOP_USER_NAME=xxx export HADOOP_USER_PASSWORD=xxx export PYSPARK_DRIVER_PYTHON=jupyter export PYSPARK_DRIVER_PYTHON_OPTS=\u0026#39;lab --port=8066 --ip=your_ip_address\u0026#39; export SPARK_HOME=/usr/local/spark-current pyspark --name your_name_data_process \\ --queue root.your_queue_name \\ --driver-memory 8g --executor-memory 13g \\ --executor-cores 3 --num-executors 100 \\ --conf spark.task.cpus=3 \\ --conf \u0026#34;spark.driver.extraJavaOptions=-Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS\u0026#34; \\ --conf \u0026#34;spark.executor.extraJavaOptions=-Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS\u0026#34;\\ --conf spark.default.parallelism=1300 \\ --conf spark.sql.shuffle.partitions=1300 \\ --conf spark.sql.broadcastTimeout=3600 \\ --conf spark.shuffle.memoryFraction=0.6 \\ --conf spark.yarn.executor.memoryoverhead=13000M \\ --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./mypython/py3.7_env/bin/python \\ --conf spark.port.maxRetries=300 \\ --conf spark.yarn.priority=100 \\ --archives hdfs://DClusterNmg3:8020/user/your_path/your_name/my_py37.tar#mypython \\ Execute nohup sh start_jupyter.sh \u0026gt;jupyter.log\u0026amp; to start the jupyter service. You can find the access link in jupyter.log, copy it to the browser to use.\n(Optional) Install the dark mode interface for jupyter lab, install it according to your needs, and you can switch in settings-\u0026gt;theme after installation.\npip install jupyterlab_darkside_ui -i https://pypi.tuna.tsinghua.edu.cn/simple Configuring zsh # Considering accessing the github link to install oh-my-zsh is often slow on servers, it is recommended to first install it locally and then copy it to the server, saving time on reinstalling plugins.\nLocal Installation of oh-my-zsh (MacOS) # Mac comes with zsh installed by default, so you only need to install oh-my-zsh. Execute\nsh -c \u0026#34;$(curl -fsSL https://install.ohmyz.sh/)\u0026#34; or\nsh -c \u0026#34;$(wget -O- https://install.ohmyz.sh/)\u0026#34; After installation, the shell will automatically switch from bash to zsh.\nInstall the following two plugins as needed:\nzsh-autosuggestions: records commands entered in the past and automatically predicts suggestions when entering commands again. git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions zsh-syntax-highlighting: displays different colors based on whether the shell command can be executed. git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting After installing the above two plugins, edit ~/.zshrc and add the names of the plugins you have installed to the plugins section.\nplugins=( # other plugins... zsh-autosuggestions zsh-syntax-highlighting ) Then execute source ~/.zshrc.\nServer Installation of zsh (Linux) # Unlike MacOS, Linux terminals do not come with zsh, so you need to install zsh first before configuring oh-my-zsh.\nConsidering Linux often serves as a remote server with potentially slow internet, here we choose to use the sftp command to directly copy the locally installed zsh to the server.\nput -r ~/.oh-my-zsh put ~/.zshrc On your server environment, execute the following command to download the zsh installation package.\nwget -O zsh.tar.xz https://sourceforge.net/projects/zsh/files/latest/download --no-check-certificate If downloading is not possible due to network issues, execute the command locally and use sftp to transfer it to the server.\nExecute tar -xvf zsh.tar.xz to extract the installation package, which will create a directory named zsh-5.9.\nEnter the zsh-5.9 directory, and execute the following commands in sequence to compile and install zsh. The prefix specifies the installation directory, you can create a folder for it\ncd zsh-5.9 ./configure -prefix=xxx make -j all make install After installation, add the following content to ~/.bashrc before conda activate. Change PATH to the bin directory under the installation path of zsh from the previous step, save, and exit, but do not source yet.\nexport PATH=$PATH:/home/odin/your_name/my_zsh/bin exec zsh Server Installation of oh-my-zsh (Linux) # After navigating to the home directory, use sftp get to retrieve the previously uploaded .oh-my-zsh folder and .zshrc.\nEdit ~/.zshrc and add the following sections at the end. The content below is just an example, please copy the corresponding content from your own .bashrc.\n# \u0026gt;\u0026gt;\u0026gt; conda initialize \u0026gt;\u0026gt;\u0026gt; # !! Contents within this block are managed by \u0026#39;conda init\u0026#39; !! __conda_setup=\u0026#34;$(\u0026#39;/home/odin/your_name/anaconda3/bin/conda\u0026#39; \u0026#39;shell.bash\u0026#39; \u0026#39;hook\u0026#39; 2\u0026gt; /dev/null)\u0026#34; if [ $? -eq 0 ]; then eval \u0026#34;$__conda_setup\u0026#34; else if [ -f \u0026#34;/home/odin/your_name_i/anaconda3/etc/profile.d/conda.sh\u0026#34; ]; then . \u0026#34;/home/odin/your_name_i/anaconda3/etc/profile.d/conda.sh\u0026#34; else export PATH=\u0026#34;/home/odin/your_name/anaconda3/bin:$PATH\u0026#34; fi fi unset __conda_setup # \u0026lt;\u0026lt;\u0026lt; conda initialize \u0026lt;\u0026lt;\u0026lt; conda activate py3.7_env export HADOOP_USER_NAME=xxx export HADOOP_USER_PASSWORD=xxxxx export HHOME=\u0026#39;/user/bigdata-dp/your_name\u0026#39; export LD_LIBRARY_PATH=/lib:/usr/lib:/usr/local/lib alias hls=\u0026#34;hadoop fs -ls\u0026#34; alias hget=\u0026#34;hadoop fs -get\u0026#34; alias hput=\u0026#34;hadoop fs -put\u0026#34; alias hcat=\u0026#34;hadoop fs -cat\u0026#34; alias http=\u0026#34;python -m http.server\u0026#34; alias hdu=\u0026#34;hadoop fs -du -h\u0026#34; Add the following to ~/.zshrc to prevent color display issues in zsh.\nexport TERM=xterm-256color Save and exit .zshrc, then execute source ~/.bashrc to complete the installation.\n(Optional) Change the theme: You can replace different themes by modifying ZSH_THEME=\u0026ldquo;robbyrussell\u0026rdquo; in ~/.zshrc. Refer to the content on the following webpage for replacement: https://github.com/ohmyzsh/ohmyzsh/wiki/Themes\n(Optional) Change fonts, customize zsh theme: https://juejin.cn/post/6844904178075058189#heading-32\n","date":"2024 April 3","externalUrl":null,"permalink":"/en/posts/build_jupyter_zsh/","section":"Posts","summary":"This page is translated by GPT-4","title":"Configuring Jupyter and zsh for Local and Server Environments on MacOS","type":"posts"},{"content":"","date":"2024 April 3","externalUrl":null,"permalink":"/en/tags/env-config/","section":"Tags","summary":"","title":"Env Config","type":"tags"},{"content":"","date":"2024 April 3","externalUrl":null,"permalink":"/en/tags/jupyter/","section":"Tags","summary":"","title":"Jupyter","type":"tags"},{"content":"","date":"2024 April 3","externalUrl":null,"permalink":"/en/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"","date":"2024 April 3","externalUrl":null,"permalink":"/en/tags/mac/","section":"Tags","summary":"","title":"Mac","type":"tags"},{"content":"","date":"2024 April 3","externalUrl":null,"permalink":"/en/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"2024 April 3","externalUrl":null,"permalink":"/en/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2024 April 3","externalUrl":null,"permalink":"/en/","section":"Witchcraft's space","summary":"","title":"Witchcraft's space","type":"page"},{"content":"","date":"2024-04-03","externalUrl":null,"permalink":"/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","section":"Tags","summary":"","title":"环境配置","type":"tags"},{"content":"","date":"2024-04-03","externalUrl":null,"permalink":"/tags/markdown/","section":"Tags","summary":"","title":"Markdown","type":"tags"},{"content":"不同Hugo主题对Markdown语法的支持程度不同，因此本页面用于检测不同Markdown语法在本主题中的兼容情况\n语言分块 # All I can think about is you!\nWell down! It\u0026rsquo;s good!\nNext paragraph!\n斜体 # well down\n分割线 # 粗体 # good\n粗斜体 # well\n横线 # well\n下划线 # underline\n脚注 # 要介绍的是1\n列表 # 第一点 第二点 第二第一 211 wo wowo wo 牛啊 good 212 第二第二 ho ho again 第三点 第四点 区块引用 # 区块引用\n这真是太棒了\n内部嵌套\n哇哦\n函数块 # printf()是一个C语言函数\n代码块 # int a = 0; void printALL{ for(int i = 0 ;i \u0026lt; a;i++){ cout \u0026lt;\u0026lt; \u0026#34;Ho\u0026#34;; } } 链接 # 百度官方网站 百度\nhttps://www.baidu.com\n这个链接 good\n图片 # 表格 # title1 title2 title3 one things two things three things first second third 键盘块 # shift and del = S Latex # $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n$$ f(a,b,c) = (a^2+b^2+c^2)^3 $$\nMermaid # 横向流程图 # graph LR A[方形] --\u003eB(圆角) B --\u003e C{条件a} C --\u003e|a=1| D[结果1] C --\u003e|a=2| E[结果2] F[横向流程图] 纵向流程图 # graph TD A[方形] --\u003e B(圆角) B --\u003e C{条件a} C --\u003e |a=1| D[结果1] C --\u003e |a=2| E[结果2] F[竖向流程图] 标准纵向流程图 # st=\u003estart: 开始框 op=\u003eoperation: 处理框 cond=\u003econdition: 判断框(是或否?) sub1=\u003esubroutine: 子流程 io=\u003einputoutput: 输入输出框 e=\u003eend: 结束框 st-\u003eop-\u003econd cond(yes)-\u003eio-\u003ee cond(no)-\u003esub1(right)-\u003eop UML时序图 # sequenceDiagram participant 张三 participant 李四 张三-\u003e王五: 王五你好吗？ loop 健康检查 王五-\u003e王五: 与疾病战斗 end Note right of 王五: 合理 食物 看医生... 李四--\u003e\u003e张三: 很好! 王五-\u003e李四: 你怎么样? 李四--\u003e王五: 很好! 标准UML时序图 # 对象A-\u003e对象B: 对象B你好吗?（请求） Note right of 对象B: 对象B的描述 Note left of 对象A: 对象A的描述(提示) 对象B--\u003e对象A: 我很好(响应) 对象A-\u003e对象B: 你真的好吗？ 脚注尾部 # A game company\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-04-03","externalUrl":null,"permalink":"/posts/markdown_test/","section":"文章","summary":"","title":"Markdown语法兼容性测试","type":"posts"},{"content":"","date":"2024-04-03","externalUrl":null,"permalink":"/tags/%E6%B5%8B%E8%AF%95/","section":"Tags","summary":"","title":"测试","type":"tags"},{"content":"","date":"2024-04-03","externalUrl":null,"permalink":"/series/%E6%B5%8B%E8%AF%95%E7%94%A8%E5%86%85%E5%AE%B9/","section":"Series","summary":"","title":"测试用内容","type":"series"},{"content":" 你好，世界！ # 这是本站的第一篇推文\n本站使用基于Go的Hugo引擎构建于Github Pages\n本文的剩余部分用于测试 本主题(Blowfish) 独有的各种语法功能\n测试警告语句 测试Timeline语句\nheader Repository Github建立仓库 2024.04.02 于Github建立网站代码仓库 Another Awesome Header code 代码编写 2024.04.03选取构建代码引擎 Jekyll-Hydejeck Hugo-Blowfish Shortcodes AWESOME 2024.04.03上传第一篇推文 测试嵌入Youtube视频\n","date":"2024-04-03","externalUrl":null,"permalink":"/posts/first_page/","section":"文章","summary":"","title":"Hello World","type":"posts"},{"content":"","date":"0001 January 1","externalUrl":null,"permalink":"/en/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"0001 January 1","externalUrl":null,"permalink":"/en/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"0001 January 1","externalUrl":null,"permalink":"/en/series/","section":"Series","summary":"","title":"Series","type":"series"}]